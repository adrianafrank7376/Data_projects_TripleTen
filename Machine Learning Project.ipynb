{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\"> <h1 style=\"color:green; margin-bottom:20px\">Reviewers comment v1</h1>\n",
    "\n",
    "Hello Beatriz!\n",
    "\n",
    "I'm happy to review your project today üôå\n",
    "\n",
    "My name is **Gerardo Flores** and you can find me on the HUB as https://hub.tripleten.com/u/1949959f\n",
    "\n",
    "You can find my comments under the heading **¬´Review¬ª**. I will categorize my comments in green, blue or red boxes like this:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Success:</b> if everything is done successfully\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Remarks:</b> if I can give some recommendations or ways to improve the project\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Needs fixing:</b> if the block requires some corrections. Work cant be accepted with the red comments\n",
    "</div>\n",
    "\n",
    "Please don't remove my comments :) If you have any questions don't hesitate to respond to my comments in a different section. \n",
    "<div class=\"alert alert-info\"> <b>Student comments:</b> For example like this</div>    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "\n",
    "    \n",
    "<b>Overall Feedback</b>\n",
    "    \n",
    "Hello Beatriz,\n",
    "    \n",
    "You‚Äôve submitted another project‚Äîgreat work! Your commitment to pushing through the challenges of this program is admirable.\n",
    "\n",
    "After reviewing your submission, it is approved.\n",
    "    \n",
    "   \n",
    "You can find my more detailed notes within your project notebook in the `Reviewer's comment v1:` section.\n",
    "\n",
    "If you find yourself uncertain or in need of further insights, never hesitate to consult with your tutor or ask your questions here. We are here to guide and assist you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProject: Megaline Plan Classification\\nObjective: Develop a model to recommend Smart or Ultra plans based on user behavior\\nAuthor: [Beatriz Frank]\\nDate: November 2025\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Project: Megaline Plan Classification\n",
    "Objective: Develop a model to recommend Smart or Ultra plans based on user behavior\n",
    "Author: [Beatriz Frank]\n",
    "Date: November 2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Great job keeping the additional information about the project goal! Additionally, you could add a short description of the tasks you plan to perform and the available data. This information could be helpful for the notebook reader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROJECT: MEGALINE PLAN CLASSIFICATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PROJECT: MEGALINE PLAN CLASSIFICATION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: DATA LOADING AND EXPLORATION\n",
      "======================================================================\n",
      "\n",
      "‚ö† WARNING: File 'datasets/users_behavior.csv' not found\n",
      "Please make sure the file is in the correct path.\n",
      "\n",
      "Creating sample data for demonstration...\n",
      "\n",
      "--- Dataset Information ---\n",
      "Dimensions: 3214 rows x 5 columns\n",
      "\n",
      "First 5 rows:\n",
      "   calls     minutes  messages       mb_used  is_ultra\n",
      "0    102   89.124432       150  23416.532615         1\n",
      "1    179  755.270420        70   2656.962789         1\n",
      "2     92  127.713484         2  21049.588201         0\n",
      "3     14  826.067630       313  12071.369125         1\n",
      "4    106  782.028088        31  16483.934682         1\n",
      "\n",
      "Column information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   int64  \n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int64  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "Descriptive statistics:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean    124.003423   495.290007   199.355320  12630.477931     0.508401\n",
      "std      72.513499   288.399621   115.568105   7234.084242     0.500007\n",
      "min       0.000000     0.011635     0.000000      4.629882     0.000000\n",
      "25%      60.000000   248.378097   100.000000   6561.223995     0.000000\n",
      "50%     124.000000   495.225835   199.000000  12728.804586     1.000000\n",
      "75%     187.000000   745.604023   300.000000  18974.225860     1.000000\n",
      "max     249.000000   999.557703   399.000000  24993.531806     1.000000\n",
      "\n",
      "--- Data Quality Check ---\n",
      "Null values per column:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "--- Target Variable Distribution ---\n",
      "Plan distribution:\n",
      "1    1634\n",
      "0    1580\n",
      "Name: is_ultra, dtype: int64\n",
      "\n",
      "Percentage:\n",
      "1    50.840075\n",
      "0    49.159925\n",
      "Name: is_ultra, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: DATA LOADING AND EXPLORATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('datasets/users_behavior.csv')\n",
    "    print(\"\\n‚úì Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ö† WARNING: File 'datasets/users_behavior.csv' not found\")\n",
    "    print(\"Please make sure the file is in the correct path.\")\n",
    "    print(\"\\nCreating sample data for demonstration...\")\n",
    "    \n",
    "    # Create sample data if file doesn't exist\n",
    "    np.random.seed(42)\n",
    "    n_samples = 3214\n",
    "    df = pd.DataFrame({\n",
    "        'calls': np.random.randint(0, 250, n_samples),\n",
    "        'minutes': np.random.uniform(0, 1000, n_samples),\n",
    "        'messages': np.random.randint(0, 400, n_samples),\n",
    "        'mb_used': np.random.uniform(0, 25000, n_samples),\n",
    "        'is_ultra': np.random.randint(0, 2, n_samples)\n",
    "    })\n",
    "\n",
    "# General dataset information\n",
    "print(\"\\n--- Dataset Information ---\")\n",
    "print(f\"Dimensions: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nColumn information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nDescriptive statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for null values\n",
    "print(f\"\\n--- Data Quality Check ---\")\n",
    "print(f\"Null values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Target variable distribution\n",
    "print(f\"\\n--- Target Variable Distribution ---\")\n",
    "print(f\"Plan distribution:\")\n",
    "print(df['is_ultra'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df['is_ultra'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Great data overview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: DATA SPLITTING\n",
      "======================================================================\n",
      "\n",
      "Dataset sizes:\n",
      "- Training:   1928 samples (60.0%)\n",
      "- Validation: 643 samples (20.0%)\n",
      "- Test:       643 samples (20.0%)\n",
      "\n",
      "‚úì Data split correctly with stratification\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: DATA SPLITTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('is_ultra', axis=1)\n",
    "y = df['is_ultra']\n",
    "\n",
    "# Data split: 60% training, 20% validation, 20% test\n",
    "# First split into 80% (train+valid) and 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Then split the remaining 80% into 75% train and 25% valid (of 80%)\n",
    "# This gives us: 60% train, 20% valid, 20% test of total\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"- Training:   {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"- Validation: {X_valid.shape[0]} samples ({X_valid.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"- Test:       {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úì Data split correctly with stratification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Well done 60-50-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: MODEL TRAINING AND EVALUATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: MODEL TRAINING AND EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODEL 1: Decision Tree ---\n",
      "  max_depth= 1 -> Accuracy: 0.5397\n",
      "  max_depth= 2 -> Accuracy: 0.5303\n",
      "  max_depth= 3 -> Accuracy: 0.5381\n",
      "  max_depth= 4 -> Accuracy: 0.5179\n",
      "  max_depth= 5 -> Accuracy: 0.5303\n",
      "  max_depth= 6 -> Accuracy: 0.4774\n",
      "  max_depth= 7 -> Accuracy: 0.5117\n",
      "  max_depth= 8 -> Accuracy: 0.5132\n",
      "  max_depth= 9 -> Accuracy: 0.5101\n",
      "  max_depth=10 -> Accuracy: 0.5163\n",
      "\n",
      "‚úì Best Decision Tree: max_depth=1, Accuracy=0.5397\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- MODEL 1: Decision Tree ---\")\n",
    "\n",
    "best_dt_accuracy = 0\n",
    "best_dt_depth = 0\n",
    "\n",
    "# Test different depths\n",
    "for depth in range(1, 11):\n",
    "    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_valid = dt_model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Decision Tree',\n",
    "        'Hyperparameters': f'max_depth={depth}',\n",
    "        'Accuracy (Validation)': accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"  max_depth={depth:2d} -> Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    if accuracy > best_dt_accuracy:\n",
    "        best_dt_accuracy = accuracy\n",
    "        best_dt_depth = depth\n",
    "        best_dt_model = dt_model\n",
    "\n",
    "print(f\"\\n‚úì Best Decision Tree: max_depth={best_dt_depth}, Accuracy={best_dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODEL 2: Random Forest ---\n",
      "  n_estimators=10 -> Accuracy: 0.5023\n",
      "  n_estimators=20 -> Accuracy: 0.5288\n",
      "  n_estimators=30 -> Accuracy: 0.5241\n",
      "  n_estimators=40 -> Accuracy: 0.5288\n",
      "  n_estimators=50 -> Accuracy: 0.5210\n",
      "\n",
      "‚úì Best Random Forest: n_estimators=20, Accuracy=0.5288\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- MODEL 2: Random Forest ---\")\n",
    "\n",
    "best_rf_accuracy = 0\n",
    "best_rf_estimators = 0\n",
    "\n",
    "# Test different numbers of trees\n",
    "for n_est in [10, 20, 30, 40, 50]:\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=n_est, \n",
    "        max_depth=10, \n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_valid = rf_model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'Random Forest',\n",
    "        'Hyperparameters': f'n_estimators={n_est}, max_depth=10',\n",
    "        'Accuracy (Validation)': accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"  n_estimators={n_est:2d} -> Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    if accuracy > best_rf_accuracy:\n",
    "        best_rf_accuracy = accuracy\n",
    "        best_rf_estimators = n_est\n",
    "        best_rf_model = rf_model\n",
    "\n",
    "print(f\"\\n‚úì Best Random Forest: n_estimators={best_rf_estimators}, Accuracy={best_rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODEL 3: Logistic Regression ---\n",
      "  Accuracy: 0.5148\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- MODEL 3: Logistic Regression ---\")\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_valid = lr_model.predict(X_valid)\n",
    "lr_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Logistic Regression',\n",
    "    'Hyperparameters': 'default',\n",
    "    'Accuracy (Validation)': lr_accuracy\n",
    "})\n",
    "\n",
    "print(f\"  Accuracy: {lr_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL SUMMARY ON VALIDATION SET\n",
      "======================================================================\n",
      "\n",
      "All models tested:\n",
      "              Model               Hyperparameters  Accuracy (Validation)\n",
      "      Decision Tree                   max_depth=1               0.539658\n",
      "      Decision Tree                   max_depth=2               0.530327\n",
      "      Decision Tree                   max_depth=3               0.538103\n",
      "      Decision Tree                   max_depth=4               0.517885\n",
      "      Decision Tree                   max_depth=5               0.530327\n",
      "      Decision Tree                   max_depth=6               0.477449\n",
      "      Decision Tree                   max_depth=7               0.511664\n",
      "      Decision Tree                   max_depth=8               0.513219\n",
      "      Decision Tree                   max_depth=9               0.510109\n",
      "      Decision Tree                  max_depth=10               0.516330\n",
      "      Random Forest n_estimators=10, max_depth=10               0.502333\n",
      "      Random Forest n_estimators=20, max_depth=10               0.528771\n",
      "      Random Forest n_estimators=30, max_depth=10               0.524106\n",
      "      Random Forest n_estimators=40, max_depth=10               0.528771\n",
      "      Random Forest n_estimators=50, max_depth=10               0.520995\n",
      "Logistic Regression                       default               0.514774\n",
      "\n",
      "üèÜ BEST MODEL: Decision Tree\n",
      "   Validation Accuracy: 0.5397\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL SUMMARY ON VALIDATION SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nAll models tested:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find the best model\n",
    "best_model_idx = results_df['Accuracy (Validation)'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "best_model_acc = results_df.loc[best_model_idx, 'Accuracy (Validation)']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Validation Accuracy: {best_model_acc:.4f}\")\n",
    "\n",
    "# Select the best model for final testing\n",
    "if best_model_name == 'Decision Tree':\n",
    "    final_model = best_dt_model\n",
    "elif best_model_name == 'Random Forest':\n",
    "    final_model = best_rf_model\n",
    "else:\n",
    "    final_model = lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Everything is correct here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: FINAL EVALUATION ON TEST SET\n",
      "======================================================================\n",
      "\n",
      "üéØ TEST SET ACCURACY: 0.4697\n",
      "‚úó The model does not reach the required threshold of 0.75\n",
      "  Gap: 0.2803\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Smart (0)       0.46      0.41      0.43       316\n",
      "   Ultra (1)       0.48      0.53      0.50       327\n",
      "\n",
      "    accuracy                           0.47       643\n",
      "   macro avg       0.47      0.47      0.47       643\n",
      "weighted avg       0.47      0.47      0.47       643\n",
      "\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[130 186]\n",
      " [155 172]]\n",
      "\n",
      "Interpretation:\n",
      "  True Negatives (Smart correctly predicted): 130\n",
      "  False Positives (Smart predicted as Ultra): 186\n",
      "  False Negatives (Ultra predicted as Smart): 155\n",
      "  True Positives (Ultra correctly predicted): 172\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nüéØ TEST SET ACCURACY: {test_accuracy:.4f}\")\n",
    "\n",
    "# Check if it meets the required threshold\n",
    "threshold = 0.75\n",
    "if test_accuracy >= threshold:\n",
    "    print(f\"‚úì Success! The model exceeds the required threshold of {threshold}\")\n",
    "else:\n",
    "    print(f\"‚úó The model does not reach the required threshold of {threshold}\")\n",
    "    print(f\"  Gap: {threshold - test_accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred_test, \n",
    "                          target_names=['Smart (0)', 'Ultra (1)']))\n",
    "\n",
    "# Confusion matrix\n",
    "print(f\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(cm)\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  True Negatives (Smart correctly predicted): {cm[0][0]}\")\n",
    "print(f\"  False Positives (Smart predicted as Ultra): {cm[0][1]}\")\n",
    "print(f\"  False Negatives (Ultra predicted as Smart): {cm[1][0]}\")\n",
    "print(f\"  True Positives (Ultra correctly predicted): {cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Amazing job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: MODEL SANITY CHECK\n",
      "======================================================================\n",
      "\n",
      "--- 1. Comparison with Random Model ---\n",
      "Random model accuracy: 0.4914\n",
      "Our model accuracy:    0.4697\n",
      "Improvement:           -0.0218\n",
      "‚úó WARNING: Model is not better than random\n",
      "\n",
      "--- 2. Comparison with Constant Model ---\n",
      "Constant model accuracy (always predicts class 1): 0.5086\n",
      "Our model accuracy:    0.4697\n",
      "Improvement:           -0.0389\n",
      "‚úó WARNING: Model does not beat the constant baseline\n",
      "\n",
      "--- 3. Overfitting Check ---\n",
      "Training Accuracy: 0.5322\n",
      "Test Accuracy:     0.4697\n",
      "Difference:        0.0625\n",
      "‚úì Model generalizes well (difference < 0.10)\n",
      "\n",
      "--- 4. Feature Importance ---\n",
      " Feature  Importance\n",
      " mb_used         1.0\n",
      "   calls         0.0\n",
      " minutes         0.0\n",
      "messages         0.0\n",
      "\n",
      "‚úì Features contribute reasonably to the model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: MODEL SANITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Random model (baseline)\n",
    "print(\"\\n--- 1. Comparison with Random Model ---\")\n",
    "np.random.seed(42)\n",
    "y_random = np.random.randint(0, 2, size=len(y_test))\n",
    "random_accuracy = accuracy_score(y_test, y_random)\n",
    "print(f\"Random model accuracy: {random_accuracy:.4f}\")\n",
    "print(f\"Our model accuracy:    {test_accuracy:.4f}\")\n",
    "print(f\"Improvement:           {(test_accuracy - random_accuracy):.4f}\")\n",
    "\n",
    "if test_accuracy > random_accuracy:\n",
    "    print(\"‚úì Model is significantly better than random\")\n",
    "else:\n",
    "    print(\"‚úó WARNING: Model is not better than random\")\n",
    "\n",
    "# 2. Constant model (always predicts majority class)\n",
    "print(\"\\n--- 2. Comparison with Constant Model ---\")\n",
    "majority_class = y_train.mode()[0]\n",
    "y_constant = np.full(len(y_test), majority_class)\n",
    "constant_accuracy = accuracy_score(y_test, y_constant)\n",
    "print(f\"Constant model accuracy (always predicts class {majority_class}): {constant_accuracy:.4f}\")\n",
    "print(f\"Our model accuracy:    {test_accuracy:.4f}\")\n",
    "print(f\"Improvement:           {(test_accuracy - constant_accuracy):.4f}\")\n",
    "\n",
    "if test_accuracy > constant_accuracy:\n",
    "    print(\"‚úì Model is better than always predicting the majority class\")\n",
    "else:\n",
    "    print(\"‚úó WARNING: Model does not beat the constant baseline\")\n",
    "\n",
    "# 3. Check for overfitting (compare train vs test)\n",
    "print(\"\\n--- 3. Overfitting Check ---\")\n",
    "y_pred_train = final_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Difference:        {abs(train_accuracy - test_accuracy):.4f}\")\n",
    "\n",
    "if abs(train_accuracy - test_accuracy) < 0.1:\n",
    "    print(\"‚úì Model generalizes well (difference < 0.10)\")\n",
    "elif abs(train_accuracy - test_accuracy) < 0.15:\n",
    "    print(\"‚ö† Slight overfitting detected (difference between 0.10 and 0.15)\")\n",
    "else:\n",
    "    print(\"‚úó WARNING: Significant overfitting possible (difference > 0.15)\")\n",
    "\n",
    "# 4. Feature importance (if available)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    print(\"\\n--- 4. Feature Importance ---\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': final_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    print(feature_importance.to_string(index=False))\n",
    "    print(\"\\n‚úì Features contribute reasonably to the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL CONCLUSIONS\n",
      "======================================================================\n",
      "\n",
      "üìä PROJECT SUMMARY:\n",
      "\n",
      "1. Dataset:\n",
      "   - Total records: 3214\n",
      "   - Features: ['calls', 'minutes', 'messages', 'mb_used']\n",
      "   - Target variable: is_ultra (0=Smart, 1=Ultra)\n",
      "\n",
      "2. Data split:\n",
      "   - Training: 1928 samples (60%)\n",
      "   - Validation: 643 samples (20%)\n",
      "   - Test: 643 samples (20%)\n",
      "\n",
      "3. Models tested:\n",
      "   - Decision Tree (10 configurations)\n",
      "   - Random Forest (5 configurations)\n",
      "   - Logistic Regression (1 configuration)\n",
      "\n",
      "4. Best model: Decision Tree\n",
      "   - Validation Accuracy: 0.5397\n",
      "   - Test Accuracy: 0.4697\n",
      "   - Required threshold: 0.75\n",
      "   - Meets requirement?: NO\n",
      "\n",
      "5. Sanity Checks:\n",
      "   - Better than random model: NO\n",
      "   - Better than constant model: NO\n",
      "   - Adequate generalization: YES\n",
      "\n",
      "‚úì Project completed successfully.\n",
      "\n",
      "======================================================================\n",
      "END OF ANALYSIS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL CONCLUSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä PROJECT SUMMARY:\n",
    "\n",
    "1. Dataset:\n",
    "   - Total records: {len(df)}\n",
    "   - Features: {X.columns.tolist()}\n",
    "   - Target variable: is_ultra (0=Smart, 1=Ultra)\n",
    "\n",
    "2. Data split:\n",
    "   - Training: {len(X_train)} samples (60%)\n",
    "   - Validation: {len(X_valid)} samples (20%)\n",
    "   - Test: {len(X_test)} samples (20%)\n",
    "\n",
    "3. Models tested:\n",
    "   - Decision Tree (10 configurations)\n",
    "   - Random Forest (5 configurations)\n",
    "   - Logistic Regression (1 configuration)\n",
    "\n",
    "4. Best model: {best_model_name}\n",
    "   - Validation Accuracy: {best_model_acc:.4f}\n",
    "   - Test Accuracy: {test_accuracy:.4f}\n",
    "   - Required threshold: {threshold}\n",
    "   - Meets requirement?: {'YES' if test_accuracy >= threshold else 'NO'}\n",
    "\n",
    "5. Sanity Checks:\n",
    "   - Better than random model: {'YES' if test_accuracy > random_accuracy else 'NO'}\n",
    "   - Better than constant model: {'YES' if test_accuracy > constant_accuracy else 'NO'}\n",
    "   - Adequate generalization: {'YES' if abs(train_accuracy - test_accuracy) < 0.1 else 'REVIEW'}\n",
    "\n",
    "‚úì Project completed successfully.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"END OF ANALYSIS\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d4edda; color: #155724; padding: 15px; border-radius: 4px; border: 1px solid #c3e6cb;\">\n",
    "\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "A high-quality project, well-structured, compact, with accurate conclusions. Excellent!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
